{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse-Engineering Visualizations (REV)\n",
    "\n",
    "REV([paper](http://idl.cs.washington.edu/papers/reverse-engineering-vis/)) is a text analysis pipeline which detects text elements in a chart, classifies their role (e.g., chart title, x-axis label, y-axis title, etc.), and recovers the text content using optical character recognition. It also uses a Convolutional Neural Network for mark type classification. Using the identified text elements and graphical mark type, it infers the encoding specification of an input chart image.\n",
    "\n",
    "Our pipeline consist of the following steps:\n",
    "\n",
    "* Text localization and recognition\n",
    "* Text role classification \n",
    "* Mark type classification \n",
    "* Specification generation\n",
    "\n",
    "## Installation\n",
    "You first need to download our code:  \n",
    "```sh\n",
    "git clone git@github.com:visual-ds/rev.git\n",
    "```\n",
    "\n",
    "Then, download the data and models are in the following \n",
    "[link](https://drive.google.com/drive/folders/1x_Um1uAT1rUfoiBHXOFXDH-CDJ2xNS5V?usp=sharing).\n",
    "You have to unzip the files in the project folder. \n",
    "\n",
    "\n",
    "### Dependencies\n",
    "* You can use any package manager to install the basic dependencies, we suggest creating an environment in conda:\n",
    "\n",
    "```sh \n",
    "    conda env create -f env.yml\n",
    "```\n",
    "\n",
    "\n",
    "* Darknet\n",
    "    \n",
    "    For text mask detection we use a modified version of Darknet, available in our fork ([visual-ds/darknet](https://github.com/visual-ds/darknet))\n",
    "    - First, you have to clone the repository and make command:\n",
    "  \n",
    "        ```sh\n",
    "            git clone git@github.com:visual-ds/darknet.git\n",
    "            cd darknet\n",
    "            make\n",
    "        ```\n",
    "        \n",
    "    - Then, set the path to the darknet executable in the `config.json` file:\n",
    "    \n",
    "        ```js\n",
    "            \"darknet_lib_path\": \"[replace_with_your_darknet_folder_path]./darknet\"\n",
    "        ```\n",
    "  \n",
    "\n",
    "\n",
    "## Using our API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Chart usage\n",
    "\n",
    "Our API works with objects of the class `Chart`. A chart is composed of an image ( visualization) and the text elements (texts, text boxes, and text roles).\n",
    "\n",
    "\n",
    "In this example, we use the image `examples/image.png` and a CSV file that contains the information of the text elements `examples/image-texts.csv` with the following format:\n",
    "\n",
    "```CSV\n",
    "id,x,y,width,height,text,type\n",
    "1,30,5,19,17,\"45\",y-axis-label\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rev.chart import Chart\n",
    "\n",
    "chart = Chart('examples/image.png', text_from=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter `text_from` means:\n",
    "- **0**: read information from ground truth data: **'{image_name}-texts.csv'**\n",
    "- **1**: read information from ground truth boxes and output of text role classification and output of OCR: **'{image_name}-pred1-texts.csv'**\n",
    "- **2**: read information from output of text localization and output of text role classification, and output of OCR. : **'{image_name}-pred2-texts.csv'**\n",
    "\n",
    "> In some cases, it is possible we do not have access to the information of the text elements, so we can infer them using our pipeline.\n",
    "Also, we can write the information files using the methods of the `Chart` class:\n",
    "````Python\n",
    "    # Create a new chart\n",
    "    chart = Chart('examples/image.png', text_from=2)\n",
    "    \n",
    "    # Infer the text boxes information\n",
    "    inferred_text_boxes = ... #(we will explain each step of the pipeline further)\n",
    "    \n",
    "    # Set the inferred text boxes to the chart\n",
    "    chart.text_boxes = inferred_text_boxes\n",
    "    \n",
    "    # Save the file with the information\n",
    "    chart.save_text_boxes()\n",
    "````\n",
    "\n",
    "> In this example, the `text_from=2` parameter indicates that even though the `examples/image-pred2-texts.csv` file does not yet exist, all the information will be saved in a new file with that name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text localization and recognition\n",
    "\n",
    "For text localization and recognition we must first create an object of the class `TextLocalizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rev.text.localizer import TextLocalizer\n",
    "\n",
    "localizer = TextLocalizer(method='default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we instantiate an object of the `TextLocalizer` class, it is possible to choose the method we will use with the `method` parameter, which allows us to choose between two methods: \n",
    "\n",
    "- **default**: uses the same technique proposed in this paper.\n",
    "- **pixel_link**: uses the technique presented in en ['PixelLink: Detecting Scene Text via Instance Segmentation'](https://arxiv.org/abs/1801.01315).\n",
    "\n",
    "Then we use the `localize` method that receives a list of charts as input and returns the text boxes and text for each chart in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text_boxes = localizer.localize([chart])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in this example, we only use one chart, we will take the first element of the returned list, which contains the text boxes and texts of our chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_text_boxes = all_text_boxes[0]\n",
    "for text_box in chart_text_boxes:\n",
    "    print(text_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create a copy of the original chart to which we assign the text boxes and save a new file with the calculated information (`examples/image-pred2-texts.csv`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_chart = chart.copy(text_from=2)\n",
    "new_chart.text_boxes = chart_text_boxes\n",
    "new_chart.save_text_boxes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also save an image where we can visualize the results at this stage of the pipeline (`examples/image-pred2-debug.png`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_chart.save_debug_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![chart example](examples/image-pred2-debug.png \"Chart debug example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text role classification\n",
    "\n",
    "For the text role classification task, we need to instantiate an object of the `TextClassifier` class and use the `classify` method that receives as input a list of charts and returns the labels with the text roles for each chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rev.text import TextClassifier\n",
    "\n",
    "text_clf = TextClassifier('default')\n",
    "all_text_type_preds = text_clf.classify([chart])\n",
    "\n",
    "text_type_preds = all_text_type_preds[0]\n",
    "\n",
    "for text_box, type_rol in zip(chart.text_boxes , text_type_preds):\n",
    "    print(text_box.text,':',type_rol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training text role classifier\n",
    "\n",
    "\n",
    "It is possible to train our model to classify text roles. To achieve this, we need a CSV file containing the features for each textbox in the image and the type label (role) that we will use for the training. Check the file `data/features_all.csv` for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data/features_all.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First, we choose the features from our dataset that we will use in training, in this case, we provide the list with the features used in the paper: `rev.text.classifier.VALID_COLUMNS`.\n",
    "\n",
    "- Then we take the `type` column as the text role labels to be used in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rev.text\n",
    "features = data[rev.text.classifier.VALID_COLUMNS]\n",
    "types = data['type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finally, we created an instance of the `TextClassifier` class and used the `train` method that receives as parameters the features and labels that will be used in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = TextClassifier()\n",
    "text_clf.train(features, types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature extraction\n",
    "\n",
    "We provide the `feature_extractor.from_chart` function for extracting features from a chart, and you can build your feature file for training from new charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rev.text import feature_extractor\n",
    "text_features = feature_extractor.from_chart(chart)\n",
    "text_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mark type classifier\n",
    "\n",
    "The `MarkClassifier` class is used to classify the type of mark on the chart. Currently, our API has two different trained models.\n",
    "\n",
    "- **charts5cats**\n",
    "    \n",
    "    There are five categories to classify: \n",
    "    - area \n",
    "    - bar\n",
    "    - line\n",
    "    - plotting_symbol\n",
    "    - undefined.\n",
    "    \n",
    "    \n",
    "- **revision**\n",
    "    \n",
    "    There are ten categories to classify, the same ones presented in the paper [ReVision: Automated Classification, Analysis and Redesign of Chart Images](http://vis.stanford.edu/papers/revision): \n",
    "    - AreaGraph\n",
    "    - BarGraph\n",
    "    - LineGraph\n",
    "    - Map \n",
    "    - ParetoChart \n",
    "    - PieChart \n",
    "    - RadarPlot \n",
    "    - ScatterGraph\n",
    "    - Table \n",
    "    - VennDiagram\n",
    "\n",
    "The `classify` method also receives a list of charts and returns a list with the predicted marks for each chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/mark_classifier/charts5cats/deploy.prototxt\n",
      "models/mark_classifier/charts5cats/snapshots/model_iter_50000.caffemodel\n",
      "models/mark_classifier/charts5cats/ilsvrc_2012_mean.npy\n",
      "joaooooooooooooooooooo [<class 'str'>]\n",
      "['area']\n"
     ]
    }
   ],
   "source": [
    "from rev.mark import MarkClassifier\n",
    "\n",
    "mark_clf = MarkClassifier(model_name = 'charts5cats')\n",
    "print(mark_clf.classify([chart]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specification generation\n",
    "\n",
    "The last step in our pipeline is the generation of the specification. The class `SpecGenerator` performs this task. To generate the specification (visual encoding) of a chart, it is only necessary to use the `generate` method that works with a list of charts and returns another list with the specifications for each chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import JSON\n",
    "from rev.spec.generator import SpecGenerator\n",
    "import json\n",
    "\n",
    "chart = Chart('examples/vega1.png', text_from=0)\n",
    "\n",
    "spec_gen = SpecGenerator()\n",
    "spec = spec_gen.generate([chart])\n",
    "JSON(spec[0], expanded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The complete pipeline\n",
    "\n",
    "Here is an example of how to use the API to generate the specification from a chart image from scratch and without any other information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import JSON\n",
    "from rev.spec.generator import SpecGenerator\n",
    "import json\n",
    "\n",
    "from rev.chart import Chart\n",
    "from rev.text.localizer import TextLocalizer\n",
    "from rev.text import TextClassifier\n",
    "\n",
    "# Cargamos un chart\n",
    "chart = Chart('examples/image.png')\n",
    "\n",
    "# Text localization and recognition:\n",
    "localizer = TextLocalizer()\n",
    "\n",
    "# Asignamos la información de textboxes que calculamos\n",
    "text_boxes = localizer.localize([chart])\n",
    "chart.text_boxes = text_boxes[0]\n",
    "\n",
    "# Obtenemos los roles para cada textbox\n",
    "text_clf = TextClassifier('default')\n",
    "text_type_preds = text_clf.classify([chart])\n",
    "\n",
    "# Asignamos el rol a cada textbox del chart\n",
    "for (text_box, role) in zip(chart.text_boxes, text_type_preds[0]):\n",
    "    text_box.type = role\n",
    "\n",
    "# Generamos la especificación (este método internamente también obtiene el tipo marca del chart)\n",
    "spec_gen = SpecGenerator()\n",
    "spec = spec_gen.generate([chart])\n",
    "JSON(spec[0], expanded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scripts\n",
    "Some usefull script to reproduce results from paper: \n",
    "```shell\n",
    "\n",
    "# run text localization and recognition in multiple charts\n",
    "python scripts/run_box_predictor.py multiple /data/academic.txt\n",
    "python scripts/run_box_predictor.py multiple /data/quartz.txt\n",
    "python scripts/run_box_predictor.py multiple /data/vega.txt\n",
    "\n",
    "# code to rate the text-role classifier (Table 4 from paper)\n",
    "python scripts/rate_text_role_classifier.py features data/features_academic.csv\n",
    "python scripts/rate_text_role_classifier.py features data/features_quartz.csv\n",
    "python scripts/rate_text_role_classifier.py features data/features_vega.csv\n",
    "\n",
    "# script to extract features\n",
    "python scripts/run_feature_extraction.py multiple data/academic.txt out.csv\n",
    "\n",
    "# train text-role classifier\n",
    "python scripts/run_text_role_classifier.py train data/features_all.csv out.plk\n",
    "\n",
    "# run text-role classifier in a chart to test\n",
    "python scripts/run_text_role_classifier.py single examples/vega1.png\n",
    "\n",
    "# run text-role classifier in multiple charts\n",
    "python scripts/run_text_role_classifier.py multiple data/academic.txt\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
