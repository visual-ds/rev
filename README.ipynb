{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse-Engineering Visualizations (REV)\n",
    "\n",
    "[paper](http://idl.cs.washington.edu/papers/reverse-engineering-vis/) | [pretrained models](https://osf.io/wubdr/) | [darknet](https://github.com/visual-ds/darknet) \n",
    " \n",
    "REV ([paper](http://idl.cs.washington.edu/papers/reverse-engineering-vis/)) is a text analysis pipeline which detects text elements in a chart, classifies their role (e.g., chart title, x-axis label, y-axis title, etc.), and recovers the text content using optical character recognition. It also uses a Convolutional Neural Network for mark type classification. Using the identified text elements and graphical mark type, it infers the encoding specification of an input chart image.\n",
    "\n",
    "Our pipeline consist of the following steps:\n",
    "\n",
    "* Text localization and recognition\n",
    "* Text role classification\n",
    "* Mark type classification\n",
    "* Specification induction\n",
    "\n",
    "## Setup \n",
    "\n",
    "In a perfect world, the following line \n",
    "\n",
    "```sh \n",
    "ipython setup.ipy \n",
    "``` \n",
    "\n",
    "should prepare the computer for our pipeline (allowing, for instance, the execution of the cells in the notebook [Example.ipynb](https://github.com/visual-ds/rev/blob/craft/Example.ipynb)). Nevertheless, the world isn't perfect; so, we provide more details in the next paragraphs.  \n",
    "\n",
    "### Installation\n",
    "You first need to download our code:  \n",
    "```sh\n",
    "git clone git@github.com:visual-ds/rev.git\n",
    "```\n",
    "\n",
    "We are using [OSF](osf.io); the data and the models, which need to be unziped, are available in this [link](https://osf.io/wubdr/).\n",
    "\n",
    "For the posterity, we also let the previous folder with the models: it is available in [Google Drive](https://drive.google.com/drive/folders/1lXpoi4lwUW3ZZCojq0bHnJTubSmStKhJ). \n",
    "\n",
    "#### Dependencies\n",
    "* You can use any package manager to install the basic dependencies, we suggest creating an environment in conda:\n",
    "\n",
    "```sh\n",
    "    conda env create -f env.yml\n",
    "```\n",
    "> Note: If when calling the `classify` method of the `MarkClassifier` class\n",
    ">1. You get the following error:\n",
    ">```sh\n",
    "> TypeError _open() got an unexpected keyword argument 'as_grey'\n",
    ">```\n",
    "> replace line 296 in the `[your_library_path]/caffe/io.py` file:\n",
    ">````Python\n",
    ">img = skimage.img_as_float(skimage.io.imread(filename, as_grey=not color)).astype(np.float32)\n",
    ">````\n",
    "> by:\n",
    "> ````Python\n",
    ">img = skimage.img_as_float(skimage.io.imread(filename, as_gray=not color)).astype(np.float32)\n",
    ">    ````\n",
    ">2. You get the following error:\n",
    ">```sh\n",
    ">TypeError: 'float' object cannot be interpreted as an integer\n",
    ">```\n",
    "> replace line 95 of the `[your_library_path]/caffe/classifier.py` file :\n",
    ">````Python\n",
    ">predictions = predictions.reshape((len(predictions) / 10, 10, -1))\n",
    ">````\n",
    ">by:\n",
    ">````Python\n",
    ">predictions = predictions.reshape((len(predictions) // 10, 10, -1))\n",
    ">````\n",
    "\n",
    "* Darknet\n",
    "\n",
    "    For text mask detection we use a modified version of Darknet, available in our fork ([visual-ds/darknet](https://github.com/visual-ds/darknet))\n",
    "    - First, you have to clone the repository and make command:\n",
    "\n",
    "        ```sh\n",
    "            git clone git@github.com:visual-ds/darknet.git\n",
    "            cd darknet\n",
    "            make\n",
    "        ```\n",
    "\n",
    "    - Then, set the path to the darknet executable in the `config.json` file:\n",
    "\n",
    "        ```js\n",
    "            \"darknet_lib_path\": \"[replace_with_your_darknet_folder_path]./darknet\"\n",
    "        ```\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using our API \n",
    "\n",
    "### Basic Chart usage\n",
    "\n",
    "Our API works with objects of the class `Chart`. A chart is composed of an image ( visualization) and the text elements (texts, text boxes, and text roles).\n",
    "\n",
    "\n",
    "In this example, we use the image `examples/image.png` and a CSV file that contains the information of the text elements `examples/image-texts.csv` with the following format:\n",
    "\n",
    "```CSV\n",
    "id,x,y,width,height,text,type\n",
    "1,30,5,19,17,\"45\",y-axis-label\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rev.chart import Chart\n",
    "\n",
    "chart = Chart('examples/image.png', text_from=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!---\n",
    "The parameter `text_from` means:\n",
    "- **0**: read information from ground truth data: **'{image_name}-texts.csv'**\n",
    "- **1**: read information from ground truth boxes and output of text role classification and output of OCR: **'{image_name}-pred1-texts.csv'**\n",
    "- **2**: read information from output of text localization and output of text role classification, and output of OCR. : **'{image_name}-pred2-texts.csv'**\n",
    "!--->\n",
    "\n",
    "The parameter 'text_from' means:\n",
    "- **0**: read ground truth data:\n",
    "    - '{image_name}-texts.csv'\n",
    "    - '{image_name}-mask.png'\n",
    "    - '{image_name}-debug.png'  \n",
    "    \n",
    "    \n",
    "- **1**: read text from 'pred1', i.e., ground truth boxes and output of text role classification and output of OCR:\n",
    "    - '{image_name}-pred1-texts.csv'\n",
    "    - '{image_name}-pred1-mask.png'\n",
    "    - '{image_name}-pred1-debug.png'\n",
    "    \n",
    "    \n",
    "- **2**: read text from 'pred2', i.e., output of text localization and output of text role classification, and output of OCR:\n",
    "    - '{image_name}-pred2-texts.csv'\n",
    "    - '{image_name}-pred2-mask.png'\n",
    "    - '{image_name}-pred2-debug.png'\n",
    "\n",
    "\n",
    "> In some cases, it is possible we do not have access to the information of the text elements, so we can infer them using our pipeline.\n",
    "Also, we can write the information files using the methods of the `Chart` class:\n",
    "````Python\n",
    "    # Create a new chart\n",
    "    chart = Chart('examples/image.png', text_from=2)\n",
    "    \n",
    "    # Infer the text boxes information\n",
    "    inferred_text_boxes = ... #(we will explain each step of the pipeline further)\n",
    "    \n",
    "    # Set the inferred text boxes to the chart\n",
    "    chart.text_boxes = inferred_text_boxes\n",
    "    \n",
    "    # Save the file with the information\n",
    "    chart.save_text_boxes()\n",
    "````\n",
    "\n",
    "> In this example, the `text_from=2` parameter indicates that even though the `examples/image-pred2-texts.csv` file does not yet exist, all the information will be saved in a new file with that name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text localization and recognition\n",
    "\n",
    "For text localization and recognition we must first create an object of the class `TextLocalizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rev.text.localizer import TextLocalizer\n",
    "\n",
    "localizer = TextLocalizer(method='default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we instantiate an object of the `TextLocalizer` class, it is possible to choose the method we will use with the `method` parameter, which allows us to choose between two methods: \n",
    "\n",
    "- **default**: uses the same technique proposed in this paper.\n",
    "- **pixel_link**: uses the technique presented in en ['PixelLink: Detecting Scene Text via Instance Segmentation'](https://arxiv.org/abs/1801.01315). \n",
    "- **craft**: uses the technique presented in [CRAFT: Character-Region Awareness For Text detection](https://arxiv.org/abs/1904.01941).\n",
    "\n",
    "\n",
    "For CRAFT, in particular, we need to load the pretrained model; it is available [here](https://drive.google.com/open?id=1Jk4eGD7crsqCCg9C9VjCLkMN3ze8kutZ). With the pth file in hand, use the `craft_model` argument on the instantiation of `TextLocalizer` class. For instance, \n",
    "\n",
    "```python\n",
    "localizer = TextLocalizer(method = \"craft\",   \n",
    "  craft_model = \"/path/to/model.pth\")\n",
    "```\n",
    "\n",
    "Also, we can choose, at this moment, the method for the text recognition: Tesseract or Attn. For Attn, in particular, we need additional (hyper)parameters; specifically, the path to the trained model, which is available (currently) at this [repository](https://github.com/clovaai/deep-text-recognition-benchmark), and other idiosyncratic aspects of the model, which are described in the documentation. The next snippet, then, represents its usage. \n",
    "\n",
    "```python  \n",
    "localizer = TextLocalizer(method = \"craft\", \n",
    "                          craft_model = \"path/to/model\", \n",
    "                          ocr = \"attn\", \n",
    "                          attr_params = {\"saved_model\": \"path/to/model\"} \n",
    "``` \n",
    "\n",
    "Then we use the `localize` method that receives a list of charts as input and returns the text boxes and text for each chart in the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text_boxes = localizer.localize([chart])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in this example, we only use one chart, we will take the first element of the returned list, which contains the text boxes and texts of our chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_text_boxes = all_text_boxes[0]\n",
    "for text_box in chart_text_boxes:\n",
    "    print(text_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create a copy of the original chart to which we assign the text boxes and save a new file with the calculated information (`examples/image-pred2-texts.csv`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_chart = chart.copy(text_from=2)\n",
    "new_chart.text_boxes = chart_text_boxes\n",
    "new_chart.save_text_boxes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also save an image where we can visualize the results at this stage of the pipeline (`examples/image-pred2-debug.png`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_chart.save_debug_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![chart example](examples/image-pred2-debug.png \"Chart debug example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text role classification\n",
    "\n",
    "For the text role classification task, we need to instantiate an object of the `TextClassifier` class and use the `classify` method that receives as input a list of charts and returns the labels with the text roles for each chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rev.text import TextClassifier\n",
    "\n",
    "text_clf = TextClassifier('default')\n",
    "all_text_type_preds = text_clf.classify([chart])\n",
    "\n",
    "text_type_preds = all_text_type_preds[0]\n",
    "\n",
    "for text_box, type_rol in zip(chart.text_boxes , text_type_preds):\n",
    "    print(text_box.text,':',type_rol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature extraction\n",
    "\n",
    "We provide the `feature_extractor.from_chart` function for extracting features from a chart, and you can build your feature file for training from new charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rev.text import feature_extractor\n",
    "text_features = feature_extractor.from_chart(chart)\n",
    "text_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training text role classifier\n",
    "\n",
    "\n",
    "It is possible to train our model to classify text roles. To achieve this, we need a CSV file containing the features for each textbox in the image and the type label (role) that we will use for the training. Check the file `data/features_all.csv` for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data/features_all.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First, we choose the features from our dataset that we will use in training, in this case, we provide the list with the features used in the paper: `rev.text.classifier.VALID_COLUMNS`.\n",
    "\n",
    "- Then we take the `type` column as the text role labels to be used in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rev.text\n",
    "features = data[rev.text.classifier.VALID_COLUMNS]\n",
    "types = data['type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finally, we created an instance of the `TextClassifier` class and used the `train` method that receives as parameters the features and labels that will be used in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = TextClassifier()\n",
    "text_clf.train(features, types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mark type classifier\n",
    "\n",
    "The `MarkClassifier` class is used to classify the type of mark on the chart. Currently, our API has two different trained models.\n",
    "\n",
    "- **charts5cats**\n",
    "    \n",
    "    Model trained with the following five categories: \n",
    "    - area \n",
    "    - bar\n",
    "    - line\n",
    "    - plotting_symbol\n",
    "    - undefined.\n",
    "    \n",
    "    \n",
    "- **revision**\n",
    "    \n",
    "    Model trained with the following ten categories, using the data presented in the paper [ReVision: Automated Classification, Analysis and Redesign of Chart Images](http://vis.stanford.edu/papers/revision): \n",
    "    - AreaGraph\n",
    "    - BarGraph\n",
    "    - LineGraph\n",
    "    - Map \n",
    "    - ParetoChart \n",
    "    - PieChart \n",
    "    - RadarPlot \n",
    "    - ScatterGraph\n",
    "    - Table \n",
    "    - VennDiagram\n",
    "\n",
    "The `classify` method also receives a list of charts and returns a list with the predicted marks for each chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rev.mark import MarkClassifier\n",
    "\n",
    "mark_clf = MarkClassifier(model_name = 'charts5cats')\n",
    "print(mark_clf.classify([chart]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specification induction\n",
    "\n",
    "The last step in our pipeline is the generation of the specification. The class `SpecGenerator` performs this task. To generate the specification (visual encoding) of a chart, it is only necessary to use the `generate` method that works with a list of charts and returns another list with the specifications for each chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import JSON\n",
    "from rev.spec.generator import SpecGenerator\n",
    "import json\n",
    "\n",
    "chart = Chart('examples/vega1.png', text_from=0)\n",
    "\n",
    "spec_gen = SpecGenerator()\n",
    "spec = spec_gen.generate([chart])\n",
    "JSON(spec[0], expanded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The complete pipeline\n",
    "\n",
    "Here is an example of how to use the API to generate the specification from a chart image from scratch and without any other information. \n",
    "\n",
    "**Default:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import JSON\n",
    "from rev.spec.generator import SpecGenerator\n",
    "import json\n",
    "\n",
    "from rev.chart import Chart\n",
    "from rev.text.localizer import TextLocalizer\n",
    "from rev.text import TextClassifier\n",
    "\n",
    "# Load a chart\n",
    "chart = Chart('examples/image.png')\n",
    "\n",
    "# Text localization and recognition:\n",
    "localizer = TextLocalizer()\n",
    "\n",
    "# set textbox information\n",
    "text_boxes = localizer.localize([chart])\n",
    "chart.text_boxes = text_boxes[0]\n",
    "\n",
    "# Getting the roles for each textbox\n",
    "text_clf = TextClassifier('default')\n",
    "text_type_preds = text_clf.classify([chart])\n",
    "\n",
    "# Set the role for each textbox on the chart\n",
    "for (text_box, role) in zip(chart.text_boxes, text_type_preds[0]):\n",
    "    text_box.type = role\n",
    "\n",
    "# Generamos la especificación (este método internamente también obtiene el tipo marca del chart)\n",
    "spec_gen = SpecGenerator()\n",
    "spec = spec_gen.generate([chart])\n",
    "JSON(spec[0], expanded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural Network based text localization:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rev.chart import Chart \n",
    "from rev.text.localizer import TextLocalizer \n",
    "from rev.text.classifier import TextClassifier \n",
    "from rev.spec.generator import SpecGenerator \n",
    "\n",
    "import json \n",
    "\n",
    "# Hyperparameters \n",
    "attn_parameters = { \n",
    "    \"saved_model\": \"../models/attn/TPS-ResNet-BiLSTM-Attn-case-sensitive.pth\", \n",
    "} \n",
    "\n",
    "craft_params = {\n",
    "    \"text_threshold\": .7,\n",
    "    \"link_threshold\": .4,\n",
    "    \"low_text\": .4,\n",
    "    \"poly\": False,\n",
    "    \"canvas_size\": 1280,\n",
    "    \"mag_ratio\": 1.8,\n",
    "    \"cuda\": False \n",
    "} \n",
    "\n",
    "chart = Chart(\"examples/chart.png\")   \n",
    "\n",
    "text_classifier = {\n",
    "    \"default\": \"../models/text_role_classifier/text_type_classifier.pkl\" \n",
    "} \n",
    "\n",
    "localizer = TextLocalizer(\"craft\", \n",
    "                          craft_model = \"../models/craft/craft_mlt_25k.pth\", \n",
    "                          craft_params = craft_params, \n",
    "                         ocr = \"attn\", \n",
    "                         attn_params = attn_parameters)  \n",
    "\n",
    "chart.text_boxes = localizer.localize([chart], \n",
    "                                      debug = True)[0] \n",
    "\n",
    "# print(chart.text_boxes) \n",
    "\n",
    "text_clf = TextClassifier(model_checkpoint = text_classifier[\"default\"]) \n",
    "text_type_preds = text_clf.classify([chart])\n",
    "\n",
    "# Set the role for each textbox on the chart\n",
    "for (text_box, role) in zip(chart.text_boxes, text_type_preds[0]):\n",
    "    text_box.type = role\n",
    "\n",
    "# Generate specification and chart mark  \n",
    "spec_gen = SpecGenerator()\n",
    "spec = spec_gen.generate([chart]) \n",
    "\n",
    "json.loads(spec[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scripts\n",
    "Some usefull script to reproduce results from paper: \n",
    "````shell\n",
    "# run text localization and recognition in multiple charts\n",
    "python scripts/run_box_predictor.py multiple ./data/academic.txt\n",
    "python scripts/run_box_predictor.py multiple ./data/quartz.txt\n",
    "python scripts/run_box_predictor.py multiple ./data/vega.txt\n",
    "\n",
    "# script to rate the text localization module\n",
    "python scripts/rate_box_predictor.py ./data/academic.txt --mask --pad 3 --from_bbs 2\n",
    "python scripts/rate_box_predictor.py ./data/quartz.txt --mask --pad 3 --from_bbs 2\n",
    "python scripts/rate_box_predictor.py ./data/vega.txt --mask --pad 3 --from_bbs 2\n",
    "\n",
    "# script to rate the text-role classifier\n",
    "python scripts/rate_text_role_classifier.py features ./data/features_academic.csv\n",
    "python scripts/rate_text_role_classifier.py features ./data/features_quartz.csv\n",
    "python scripts/rate_text_role_classifier.py features ./data/features_vega.csv\n",
    "\n",
    "# script to extract features\n",
    "python scripts/run_feature_extraction.py multiple ./data/academic.txt out.csv\n",
    "\n",
    "# train text-role classifier\n",
    "python scripts/run_text_role_classifier.py train ./data/features_all.csv out.plk\n",
    "\n",
    "# run text-role classifier in a chart to test\n",
    "python scripts/run_text_role_classifier.py single ./examples/vega1.png\n",
    "\n",
    "# run text-role classifier in multiple charts\n",
    "python scripts/run_text_role_classifier.py multiple ./data/academic.txt\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we have a script for evaluating CRAFT; execute, for instance, \n",
    "\n",
    "```sh \n",
    "# run text localization using CRAFT \n",
    "python scripts/rate_craft.py academic \n",
    "python scripts/rate_craft.py quartz \n",
    "python scripts/rate_craft.py vega \n",
    "\n",
    "# script to rate the text localization module\n",
    "python scripts/rate_box_predictor.py ./data/academic.txt --mask --pad 2 --from_bbs 2\n",
    "python scripts/rate_box_predictor.py ./data/quartz.txt --mask --pad 2 --from_bbs 2\n",
    "python scripts/rate_box_predictor.py ./data/vega.txt --mask --pad 2 --from_bbs 2\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
