{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup \n",
    "\n",
    "[paper](http://idl.cs.washington.edu/papers/reverse-engineering-vis/) | [pretrained models](https://osf.io/wubdr/) | [darknet](https://github.com/visual-ds/darknet) \n",
    "\n",
    "The next cell will install the dependencies and, in general, prepare the environment; it will need (for the data and the pretrained models) approximately 2.5 GB of space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies \n",
    "!conda env create -f env.yml \n",
    "\n",
    "# install darknet \n",
    "!git clone https://github.com/visual-ds/darknet \n",
    "!cd darknet && make \n",
    "\n",
    "import os \n",
    "\n",
    "CWD = os.path.abspath(os.getcwd()) \n",
    "\n",
    "with open(\"config.json\", \"w\") as file: \n",
    "    config = \"\"\"{{ \n",
    "    \"darknet_lib_path\": \"{path}/./darknet\" \n",
    "}}\\n\"\"\".format(path = CWD + \"/darknet\") \n",
    "    file.write(config) \n",
    "\n",
    "#pretrained models \n",
    "print(\"Downloading models from https://osf.io/ckj5z/download\")  \n",
    "!wget https://osf.io/ckj5z/download -O models.zip \n",
    "!unzip models.zip \n",
    "\n",
    "# data \n",
    "print(\"Downloading data from https://osf.io/uwtsv/\") \n",
    "!wget https://osf.io/uwtsv/download -O data.zip \n",
    "!unzip data.zip \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines \n",
    "\n",
    "Currently, we have two methods for text localization (`craft` and `default`, that is described in the paper) and two methods for text recognition (`attn` and `tesseract`, which is the default). The general guidelines, then, of how to use it are described in the next cells; ideally, they should compute the specficiations for the chart. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"..\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import JSON\n",
    "from rev.spec.generator import SpecGenerator\n",
    "import json\n",
    "\n",
    "from rev.chart import Chart\n",
    "from rev.text.localizer import TextLocalizer\n",
    "from rev.text import TextClassifier\n",
    "\n",
    "attn_parameters = { \n",
    "    # \"image_folder\": \"imgboxes\", \n",
    "    \"saved_model\": \"../models/attn/TPS-ResNet-BiLSTM-Attn-case-sensitive.pth\", \n",
    "} \n",
    "\n",
    "text_classifier = {\n",
    "    \"default\": \"../models/text_role_classifier/text_type_classifier.pkl\" \n",
    "} \n",
    "\n",
    "# Load a chart \n",
    "quartz = \"../data/quartz/4JevQPPu.png\" # from OSF \n",
    "quartzII = \"../data/quartz/4J0AakdDl.png\" # from OSF \n",
    "chartp = \"../examples/chart.png\" \n",
    "area = \"../examples/image.png\" \n",
    "\n",
    "chart = Chart(area) \n",
    "\n",
    "# Text localization and recognition:\n",
    "localizer = TextLocalizer(ocr = \"attn\", \n",
    "                          attn_params = attn_parameters)    \n",
    "\n",
    "# set textbox information\n",
    "text_boxes = localizer.localize([chart], debug = True)\n",
    "chart.text_boxes = text_boxes[0]\n",
    "\n",
    "# print(chart.text_boxes) \n",
    "# Getting the roles for each textbox\n",
    "text_clf = TextClassifier(model_checkpoint = text_classifier[\"default\"]) \n",
    "\n",
    "text_type_preds = text_clf.classify([chart])\n",
    "\n",
    "# Set the role for each textbox on the chart\n",
    "for (text_box, role) in zip(chart.text_boxes, text_type_preds[0]):\n",
    "    text_box.type = role\n",
    "\n",
    "# Generate specification and chart mark \n",
    "spec_gen = SpecGenerator()\n",
    "spec = spec_gen.generate([chart]) \n",
    "\n",
    "json.loads(spec[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Neural Network based techniques, we need to set some hyperparameters: `cuda` is, in general, set to `False`; the others are, in this pipeline, the default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_parameters = { \n",
    "    # \"image_folder\": \"imgboxes\", \n",
    "    \"saved_model\": \"../models/attn/TPS-ResNet-BiLSTM-Attn-case-sensitive.pth\", \n",
    "} \n",
    "\n",
    "import torch \n",
    "cuda = torch.cuda.is_available() \n",
    "\n",
    "craft_params = {\n",
    "    \"text_threshold\": .7,\n",
    "    \"link_threshold\": .4,\n",
    "    \"low_text\": .4,\n",
    "    \"poly\": False,\n",
    "    \"canvas_size\": 1280,\n",
    "    \"mag_ratio\": 1.8,\n",
    "    \"cuda\": cuda \n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from rev.chart import Chart \n",
    "from rev.text.localizer import TextLocalizer \n",
    "from rev.text.classifier import TextClassifier \n",
    "from rev.spec.generator import SpecGenerator \n",
    "\n",
    "import json \n",
    "# import torch \n",
    "quartz = \"../data/quartz/4JevQPPu.png\" # from OSF \n",
    "quartzII = \"../data/quartz/4J0AakdDl.png\" # from OSF \n",
    "chartp = \"../examples/chart.png\" \n",
    "area = \"../examples/image.png\" \n",
    "vega = \"../data/vega/burtin1/mark=bar|x=Penicilin,O|y=count_*,Q.png\"\n",
    "chart = Chart(\"../data/quartz/B1LOWeGM.png\")   \n",
    "\n",
    "# cuda = torch.cuda.is_available() \n",
    "\n",
    "text_classifier = {\n",
    "    \"default\": \"../models/text_role_classifier/text_type_classifier.pkl\" \n",
    "} \n",
    "\n",
    "localizer = TextLocalizer(\"craft\", \n",
    "                          craft_model = \"../models/craft/craft_mlt_25k.pth\", \n",
    "                          craft_params = craft_params, \n",
    "                         ocr = \"attn\", \n",
    "                         attn_params = attn_parameters)  \n",
    "\n",
    "chart.text_boxes = localizer.localize([chart], \n",
    "                                      debug = True)[0] \n",
    "\n",
    "# print(chart.text_boxes) \n",
    "\n",
    "text_clf = TextClassifier(model_checkpoint = text_classifier[\"default\"]) \n",
    "text_type_preds = text_clf.classify([chart])\n",
    "\n",
    "# Set the role for each textbox on the chart\n",
    "for (text_box, role) in zip(chart.text_boxes, text_type_preds[0]):\n",
    "    text_box.type = role\n",
    "\n",
    "# Generate specification and chart mark  \n",
    "spec_gen = SpecGenerator()\n",
    "spec = spec_gen.generate([chart]) \n",
    "\n",
    "json.loads(spec[0]) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
